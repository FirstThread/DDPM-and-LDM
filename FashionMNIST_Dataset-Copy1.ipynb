{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00beb01c",
   "metadata": {},
   "source": [
    "#### Getting Started with FashionMNIST\n",
    "\n",
    "This notebook shows how to load the FashionMNIST dataset in PyTorch and illustrates what kind of samples it contains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9335503",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import ConcatDataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d0a6844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda\n",
      "The combined dataset contains 70000 samples.\n",
      "It contains objects from the following 10 classes:\n",
      "['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot'] \n",
      "\n",
      "The shape of an image tensor is: torch.Size([1, 28, 28])\n",
      "The shape of a class label is: torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device {device}')\n",
    "\n",
    "# Transformationen definieren\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normalisiert Daten auf [-1, 1]\n",
    "])\n",
    "\n",
    "\n",
    "# create an instance of the training split of the FashionMNIST dataset\n",
    "dataset_train = FashionMNIST(root='/data/FashionMNIST', train=True, download=True, transform=transform, target_transform=lambda x: torch.Tensor([x]).int())\n",
    "# now create an instance of the test split\n",
    "dataset_valid = FashionMNIST(root='/data/FashionMNIST', train=False, download=True, transform=transform, target_transform=lambda x: torch.Tensor([x]).int())\n",
    "# for our purposes we can combine the 60k training and 10k testing samples\n",
    "dataset = ConcatDataset([dataset_train, dataset_valid])\n",
    "# display some information on the dataset\n",
    "print(f'The combined dataset contains {len(dataset)} samples.')\n",
    "print(f'It contains objects from the following {len(dataset_train.classes)} classes:')\n",
    "print(dataset_train.classes, '\\n')\n",
    "# select a random sample index and load the corresponding data sample\n",
    "sample_idx = random.randrange(len(dataset))\n",
    "# \n",
    "img_tensor, class_label = dataset.__getitem__(sample_idx)\n",
    "trainloader = torch.utils.data.DataLoader(dataset_train, batch_size=2048,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "print('The shape of an image tensor is:', img_tensor.shape)\n",
    "print('The shape of a class label is:', class_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "166dbb4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image shows an instance of Dress.\n"
     ]
    }
   ],
   "source": [
    "# we can also visualize and describe a sample\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(img_tensor.squeeze(), cmap='Greys_r')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "print('The image shows an instance of ' + dataset_train.classes[class_label.item()] + '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7aa9e131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# handvoll resisdual basic blocks -> flatten -> handvoll fully conntected layers\n",
    "# resnet basic block : conv3x3 + norm_layer + non_lin + conv3x3 + normlayer\n",
    "# identity: conv1x1 + norm layer\n",
    "# output: non_lin(identity_layers(x) + [conv3x3 + norm_layer + non_lin + conv3x3 + normlayer](x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0b77ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_linear_schedule(steps, start, end):\n",
    "    step_size = (end - start) / (steps - 1)  \n",
    "    linear_schedule = []\n",
    "    for i in range(steps):\n",
    "        linear_schedule.append(start + i * step_size)\n",
    "    return linear_schedule\n",
    "\n",
    "# Function to add Gaussian noise to an image tensor\n",
    "def add_gaussian_noise(image, mean=0., std=1.):\n",
    "    eps = torch.empty_like(image).normal_(mean=0,std=1)\n",
    "    noise = eps * std + mean\n",
    "    # beta*eps + sqrt(1-beta)*image+std # (1-beta).sqrt()*image + beta*eps\n",
    "    # Clip the values to be between 0 and 1\n",
    "    # noisy_image = normalize_image(noisy_image)\n",
    "    return noise, eps\n",
    "\n",
    "def berechne_alpha_quer_x_forward_steps(anzahl_steps):\n",
    "    scheduler = create_linear_schedule(anzahl_steps, 0.0001, 0.02)\n",
    "    alphas = 1 - np.array(scheduler)\n",
    "    alphas_quer = []\n",
    "    for i in range(len(alphas)):\n",
    "        alphas_quer.append(np.prod(alphas[:i + 1]))\n",
    "    return alphas_quer\n",
    "\n",
    "def x_forward_steps(curr_image, alpha_quer):\n",
    "    alpha_quer = torch.tensor(alpha_quer, dtype=torch.float32).to(device)  # 'device' is your CUDA device\n",
    "    std = torch.sqrt(1 - alpha_quer)\n",
    "    mean = torch.sqrt(alpha_quer) * curr_image\n",
    "    new_image, eps = add_gaussian_noise(curr_image,mean=mean,std=std)\n",
    "    return new_image, eps\n",
    "\n",
    "def mache_noise_direkt_random(batch_images, total_steps=1000, device=device):\n",
    "    # Verschieben Sie den Batch auf die GPU\n",
    "    batch_images = batch_images.to(device)\n",
    "    \n",
    "    # Annahme: batch_images hat die Form [batch_size, channels, height, width]\n",
    "    batch_size = batch_images.size(0)\n",
    "    \n",
    "    alpha_quer_list = berechne_alpha_quer_x_forward_steps(total_steps)\n",
    "    alpha_quer = torch.tensor(alpha_quer_list, device=device)\n",
    "\n",
    "    noisy_batch = []\n",
    "    epsilons = []\n",
    "    anzahl_steps_array = np.empty(batch_size)\n",
    "    # for loop vernichten\n",
    "    for i in range(batch_size):\n",
    "        anzahl_steps = np.random.randint(total_steps)\n",
    "        anzahl_steps_array[i] = anzahl_steps\n",
    "        \n",
    "        image = batch_images[i]\n",
    "        noisy_image, eps = x_forward_steps(image.unsqueeze(0).to(device), alpha_quer[anzahl_steps-1])  # Verschieben auf die GPU\n",
    "        \n",
    "        noisy_batch.append(noisy_image)\n",
    "        epsilons.append(eps)\n",
    "    \n",
    "    noisy_batch_tensor = torch.cat(noisy_batch, dim=0).to(device)  # Verschieben auf die GPU\n",
    "    epsilons_tensor = torch.cat(epsilons, dim=0).to(device)  # Verschieben auf die GPU\n",
    "    \n",
    "    return noisy_batch_tensor, epsilons_tensor, anzahl_steps_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82e937fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self, in_channels, intermediate_channels, identity_downsample=None, stride=1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.expansion = 4\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels,\n",
    "            intermediate_channels,\n",
    "            kernel_size=3,\n",
    "            stride=stride,\n",
    "            padding=1,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm2d(intermediate_channels)\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            intermediate_channels,\n",
    "            intermediate_channels * self.expansion,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.bn3 = nn.BatchNorm2d(intermediate_channels * self.expansion)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.identity_downsample = identity_downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x.clone()\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "\n",
    "        if self.identity_downsample is not None:\n",
    "            identity = self.identity_downsample(identity)\n",
    "\n",
    "        x += identity\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, image_channels, num_classes):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            image_channels, 64, kernel_size=7, stride=2, padding=3, bias=False\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        # Essentially the entire ResNet architecture are in these 4 lines below\n",
    "        self.layer1 = self._make_layer(\n",
    "            block, layers[0], intermediate_channels=64, stride=1\n",
    "        )\n",
    "        self.layer2 = self._make_layer(\n",
    "            block, layers[1], intermediate_channels=128, stride=2\n",
    "        )\n",
    "        self.layer3 = self._make_layer(\n",
    "            block, layers[2], intermediate_channels=256, stride=2\n",
    "        )\n",
    "        self.layer4 = self._make_layer(\n",
    "            block, layers[3], intermediate_channels=512, stride=2\n",
    "        )\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * 4, num_classes)\n",
    "\n",
    "        #self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        #self.fc1 = nn.Linear(128 * 4, 128)\n",
    "        #self.fc2 = nn.Linear(128, 84)\n",
    "        #self.fc3 = nn.Linear(84, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fc(x)\n",
    "        #x = self.fc1(x)\n",
    "        #x = self.relu(x)\n",
    "        #x = self.fc2(x)\n",
    "        #x = self.relu(x)\n",
    "        #x = self.fc3(x)\n",
    "        \n",
    "\n",
    "        return x\n",
    "\n",
    "    def _make_layer(self, block, num_residual_blocks, intermediate_channels, stride):\n",
    "        identity_downsample = None\n",
    "        layers = []\n",
    "\n",
    "        # Either if we half the input space for ex, 56x56 -> 28x28 (stride=2), or channels changes\n",
    "        # we need to adapt the Identity (skip connection) so it will be able to be added\n",
    "        # to the layer that's ahead\n",
    "        if stride != 1 or self.in_channels != intermediate_channels * 4:\n",
    "            identity_downsample = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    self.in_channels,\n",
    "                    intermediate_channels * 4,\n",
    "                    kernel_size=1,\n",
    "                    stride=stride,\n",
    "                    bias=False,\n",
    "                ),\n",
    "                nn.BatchNorm2d(intermediate_channels * 4),\n",
    "            )\n",
    "\n",
    "        layers.append(\n",
    "            block(self.in_channels, intermediate_channels, identity_downsample, stride)\n",
    "        )\n",
    "\n",
    "        # The expansion size is always 4 for ResNet 50,101,152\n",
    "        self.in_channels = intermediate_channels * 4\n",
    "\n",
    "        # For example for first resnet layer: 256 will be mapped to 64 as intermediate layer,\n",
    "        # then finally back to 256. Hence no identity downsample is needed, since stride = 1,\n",
    "        # and also same amount of channels.\n",
    "        for i in range(num_residual_blocks - 1):\n",
    "            layers.append(block(self.in_channels, intermediate_channels))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f450ffdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNetWithParam(img_channel=1, num_classes=10):\n",
    "    return ResNet(ResidualBlock, [3, 4, 23, 3], img_channel, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da462db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    BATCH_SIZE = 2048\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    net = ResNetWithParam(img_channel=1, num_classes=10).to(device)\n",
    "    y = net(torch.randn(BATCH_SIZE, 1, 28, 28, device=device))\n",
    "    assert y.size() == torch.Size([BATCH_SIZE, 10])\n",
    "    print(y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1de0fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2048, 10])\n"
     ]
    }
   ],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4565532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU()\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (identity_downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv2): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (2): ResidualBlock(\n",
       "      (conv2): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv2): Conv2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (identity_downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv2): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (2): ResidualBlock(\n",
       "      (conv2): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (3): ResidualBlock(\n",
       "      (conv2): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv2): Conv2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (identity_downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv2): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (2): ResidualBlock(\n",
       "      (conv2): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (3): ResidualBlock(\n",
       "      (conv2): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (4): ResidualBlock(\n",
       "      (conv2): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (5): ResidualBlock(\n",
       "      (conv2): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (6): ResidualBlock(\n",
       "      (conv2): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (7): ResidualBlock(\n",
       "      (conv2): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (8): ResidualBlock(\n",
       "      (conv2): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (9): ResidualBlock(\n",
       "      (conv2): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (10): ResidualBlock(\n",
       "      (conv2): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (11): ResidualBlock(\n",
       "      (conv2): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (12): ResidualBlock(\n",
       "      (conv2): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (13): ResidualBlock(\n",
       "      (conv2): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (14): ResidualBlock(\n",
       "      (conv2): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (15): ResidualBlock(\n",
       "      (conv2): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (16): ResidualBlock(\n",
       "      (conv2): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (17): ResidualBlock(\n",
       "      (conv2): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (18): ResidualBlock(\n",
       "      (conv2): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (19): ResidualBlock(\n",
       "      (conv2): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (20): ResidualBlock(\n",
       "      (conv2): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (21): ResidualBlock(\n",
       "      (conv2): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (22): ResidualBlock(\n",
       "      (conv2): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv2): Conv2d(1024, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (identity_downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv2): Conv2d(2048, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (2): ResidualBlock(\n",
       "      (conv2): Conv2d(2048, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load(\"Fashion_MNIST_Res_Noise.pt\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b06654f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "#model = ResNetWithParam(img_channel=1, num_classes=10).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay = 0.001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=10, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30e3483",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0879fb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b89c89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "447f1c17f29a45aba9940fd27319b8bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_93551/1577260930.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  alpha_quer = torch.tensor(alpha_quer, dtype=torch.float32).to(device)  # 'device' is your CUDA device\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "Epoch: 0 | Train Loss: 1.3454204559326173 | Best Loss: 1.3454204559326173\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b5b38ec2cd74ac8908114421e8d9a82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13d5fba2d9f4483fb7eb10983a9d170b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8e5ac7266084a41b8ee780a36d7b18b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "min_loss = 1e25\n",
    "for epoch in range(10000):\n",
    "    running_loss = 0.0\n",
    "    model.train()\n",
    "    mean_epoch_loss = []\n",
    "    for i, data in tqdm(enumerate(trainloader, 0)):\n",
    "    # get the inputs; data is a list of [inputs, labels]\n",
    "        img_tensors, class_labels = [t.to(device) for t in data]\n",
    "        class_labels = class_labels.squeeze(1).long()\n",
    "        noisy_image_tensor, eps, anzahl_schritte = mache_noise_direkt_random(img_tensors)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(noisy_image_tensor)\n",
    "        loss = criterion(outputs, class_labels)\n",
    "        mean_epoch_loss.append(loss.item())\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "    loss_mean = np.mean(mean_epoch_loss)\n",
    "    scheduler.step(loss_mean)\n",
    "    if loss_mean < min_loss:\n",
    "        min_loss = loss_mean\n",
    "        torch.save(model, 'Fashion_MNIST_Res_Noise.pt')\n",
    "    if epoch%5==0:\n",
    "        print('---')\n",
    "        print(f\"Epoch: {epoch} | Train Loss: {loss_mean} | Best Loss: {min_loss}\")    \n",
    "        \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e267d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"Fashion_MNIST_Res_Noise.pt\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36dd7817",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()\n",
    "\n",
    "model.eval()\n",
    "z = np.random.randint(10000)\n",
    "data_sample = dataset_valid.__getitem__(z)\n",
    "inp_img, target = [t.to(device) for t in data_sample]\n",
    "eingabe_bild, eps, anzahl_schritte = mache_noise_direkt_random(inp_img)\n",
    "out = model(eingabe_bild.unsqueeze(0))\n",
    "i = 0\n",
    "temp = out.cpu().detach().numpy().tolist()\n",
    "x_norm = softmax(temp)\n",
    "for klasse in dataset_valid.classes:\n",
    "    print(f'{klasse}: {x_norm[0][i]}')\n",
    "    i +=1\n",
    "\n",
    "print(f\"Prediction: {dataset_valid.classes[out.argmax().cpu()]}, Reality: {dataset_valid.classes[target.item()]}\")\n",
    "plt.imshow(inp_img.squeeze().cpu(), cmap='Greys_r')\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(eingabe_bild.squeeze().cpu(), cmap=\"gray\")\n",
    "plt.title(f\"Anzahl Schritte: {anzahl_schritte}\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217926bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_img.requires_grad()\n",
    "log_out = torch.log(out)\n",
    "log_out.backward()\n",
    "dummer_gradient = inp_img.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd43c829",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff79e51d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
